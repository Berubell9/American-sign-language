{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASL_clean.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Berubell9/American-sign-language/blob/main/ASL_Images_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# American Sign Languege (ASL)"
      ],
      "metadata": {
        "id": "zXmzm0hevBUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# เชื่อมต่อไดร์ฟ\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "M7BUbGsvLOQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcUEkB26MaY9"
      },
      "outputs": [],
      "source": [
        "!pip install torchvision\n",
        "!pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path as op\n",
        "import shutil\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm \n",
        "from torchvision import datasets, models, transforms\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "import torch\n",
        "import PIL\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import seaborn as sns\n",
        "import cv2"
      ],
      "metadata": {
        "id": "74Vq5JdxTqbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ดึงรูปจากใน class train\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, train_dir,transformation):\n",
        "        self.img_labels = []\n",
        "        self.img_dirs = []\n",
        "        self.transformation = transformation\n",
        "        \n",
        "        for label in listdir(train_dir):\n",
        "            img_dirs_in_folder = [join(train_dir, label, file_name) for file_name in listdir(join(train_dir, label)) if isfile(join(train_dir, label, file_name))]\n",
        "            self.img_dirs.extend(img_dirs_in_folder)\n",
        "            self.img_labels.extend([label] * len(img_dirs_in_folder))\n",
        "            \n",
        "        self.labels_encode = {class_name: i for i , class_name in enumerate(sorted(set(self.img_labels)))}    \n",
        "    def __len__(self):\n",
        "        return len(self.img_dirs)\n",
        "    \n",
        "    def _read_img(self, img_dir):\n",
        "        return PIL.Image.open(img_dir).convert(\"RGB\")\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img = self._read_img(self.img_dirs[index])\n",
        "        np_img = np.array(img)\n",
        "        if np_img.shape[-1] != 3:\n",
        "          print(np_img.shape)\n",
        "          print(self.img_dirs[index])\n",
        "        if self.transformation : \n",
        "          img = self.transformation(img)\n",
        "        label = self.img_labels[index]\n",
        "        label = self.labels_encode[label]\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "zH0dUtD4T0fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ปรับรูปให้ขนาด 224*244\n",
        "transformation = transforms.Compose([\n",
        "  transforms.Resize((224,224)),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])                                   \n",
        "])"
      ],
      "metadata": {
        "id": "KTv1IPrQUURI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ขนาดของข้อมูลที่จะ Train\n",
        "train[0][0].shape"
      ],
      "metadata": {
        "id": "6UlK685KYmdC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e7a5bd-1257-4fb2-c3da-45774ed510cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset สำหรับ Train\n",
        "train_dataset = CustomDataset(\"...\",transformation = transformation) \n",
        "print(train_dataset.labels_encode)"
      ],
      "metadata": {
        "id": "OyYjSM3EUa5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06df29a9-d74b-498a-d59c-9f2d6944f86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'del': 26, 'nothing': 27, 'space': 28}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test set\n",
        "test_dataset = CustomDataset(\"...\",transformation = transformation) \n",
        "print(test_dataset.labels_encode)"
      ],
      "metadata": {
        "id": "Po70oyc3680B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loader"
      ],
      "metadata": {
        "id": "CLO_C_ORV33q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ลบรูปที่ไม่ใช่นามสกุล png / jpg / jpeg\n",
        "folder_dir = \"...\"\n",
        "for classes in os.listdir(folder_dir):\n",
        "    \n",
        "    for images in os.listdir(f'{folder_dir}/{classes}'):\n",
        "    \n",
        "        # ตรวจสอบว่ารูปภาพลงท้ายด้วย png / jpg / jpeg\n",
        "        if (images.endswith(\".png\") or images.endswith(\".jpg\") or images.endswith(\".jpeg\")):\n",
        "            continue\n",
        "        else:\n",
        "          print(images)\n",
        "          #ลบ\n",
        "          img_path = f\"{folder_dir}/{classes}/{images}\"\n",
        "          os.remove(img_path)\n",
        "          print(f\"{images}:removed\")\n",
        "print(\"Success\")"
      ],
      "metadata": {
        "id": "i4u-JGBMPjrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# สร้าง Pretrained model ด้วย resnet50\n",
        "model = models.resnet50(pretrained=True)"
      ],
      "metadata": {
        "id": "qPbwmyJ7V8pG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (fc): Linear(in_features=2048, out_features=29, bias=True) มาจาก print(model)\n",
        "model.fc = nn.Linear(2048, 29)"
      ],
      "metadata": {
        "id": "rSPX4iUckDXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "xGjU3FXxXqRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb9241e-965a-4f56-be24-bd0d760c401d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# จำนวน Data ทั้งหมด\n",
        "len(train_dataset)"
      ],
      "metadata": {
        "id": "V0-6_CKDXza1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8251e9ec-b7fb-46ad-f103-33472a55e89c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14498"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# เเยก Train กับ test\n",
        "# train,test = torch.utils.data.random_split(train_dataset,[14498-2000,2000])\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "PfBRrH1gXu_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# สร้าง Loss, Optimizer\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=2e-3)"
      ],
      "metadata": {
        "id": "HqIJbAdSYPNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# เช็คว่ามี GPU ที่สามารถใช้ได้มั้ย ถ้าใช้ได้นำโมเดลเข้าไปอยู่ใน GPU\n",
        "gpu = torch.cuda.is_available()\n",
        "print(gpu)\n",
        "if gpu:\n",
        "    model.cuda()"
      ],
      "metadata": {
        "id": "oRZ-MhzmYXjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03176e1a-afb4-489e-e22c-6c5dfcb1ff0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Dataset"
      ],
      "metadata": {
        "id": "Eu5EBzXYYeXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_train = len(train_loader.dataset)\n",
        "n_val = len(test_loader.dataset)"
      ],
      "metadata": {
        "id": "lhWa3vfjYi-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 1 # จำนวนการ Train\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    # ช่วง train\n",
        "    model.train()\n",
        "    train_loss, val_loss = 0, 0\n",
        "    for images, labels in tqdm(train_loader):\n",
        "        if gpu:\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(images) # คำนวณหา output (predic) จากโมเดลที่มีอยู่\n",
        "        loss = cross_entropy(pred, labels)\n",
        "        loss.backward() # คำนวณ gradient จาก loss ที่ได้\n",
        "        optimizer.step() # อัพเดทพารามิเตอร์ของโมเดล\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # ช่วง validate\n",
        "    model.eval() #เซ็ตเป็น evaluation mode\n",
        "    torch.save(model,f\"/content/drive/MyDrive/ชื่อไฟล์.pt\") # Path โมเดล ที่ Save\n",
        "    for images, labels in tqdm(test_loader):\n",
        "        if gpu:\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "        pred = model(images)\n",
        "        loss = cross_entropy(pred, labels)\n",
        "        val_loss += loss.item() * images.size(0)\n",
        "    print(\"Training loss = {}, Validation loss = {}\".format(train_loss / n_train, val_loss / n_val))"
      ],
      "metadata": {
        "id": "uI6_dbdfYy_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix ดูความเเม่นยำของเเต่ละ Class"
      ],
      "metadata": {
        "id": "-9f-3sFnZfsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CustomDataset(\"...\",transformation = transformation) \n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "vWzC28Sb6P7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ใส่ Path โมเดล\n",
        "new_model = torch.load(f\"...\") \n",
        "new_model.eval()"
      ],
      "metadata": {
        "id": "9RPiP0JcZsBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_list = []\n",
        "label_list = []\n",
        "for data, label in tqdm(test_loader):\n",
        "  pred = new_model(data.cuda()).cpu().detach()\n",
        "  pred = torch.argmax(torch.softmax(pred,dim=1),dim=1)\n",
        "  pred_list.extend(pred.numpy().tolist())\n",
        "  label_list.extend(label.numpy().tolist())"
      ],
      "metadata": {
        "id": "aBOaqdiQaJ3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encode = {\n",
        "        'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'del': 26, 'nothing': 27, 'space': 28\n",
        "    }\n",
        "label_decode = {value: key for key, value in label_encode.items()}\n",
        "\n",
        "pred_key = [label_decode[pred] for pred in pred_list]\n",
        "label_key = [label_decode[label] for label in label_list]\n",
        "labels = list(label_encode.keys())"
      ],
      "metadata": {
        "id": "ewOmjcXjgXrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfm = confusion_matrix(label_key ,pred_key, labels = list(label_encode.keys()))"
      ],
      "metadata": {
        "id": "M6bLhOhWaLRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ความเเม่นยำ(Accuracy) ของทุกคลาส ,ทั้งหมด \n",
        "df_cm = pd.DataFrame(cfm/np.sum(cfm, axis = -1) *100, index = [i for i in labels],columns = [i for i in labels])\n",
        "plt.figure(figsize = (12*2,7*2))\n",
        "sns.heatmap(df_cm, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wWBFZPg9aNqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ความเเม่นยำ(Accuracy) ของทุกคลาส ,ทั้งหมด \n",
        "print(classification_report(label_key ,pred_key, labels = list(label_encode.keys())))"
      ],
      "metadata": {
        "id": "TJC6WHYvaQ0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ทำนายผลจาก Test ข้างนอก (Predict)"
      ],
      "metadata": {
        "id": "W0VB7iBPaUHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ใส่ Path ภาพ\n",
        "images = '...' \n",
        "\n",
        "# ใส่ Path โมเดล\n",
        "new_model = torch.load(f\"...\")\n",
        "new_model.eval()"
      ],
      "metadata": {
        "id": "j_d6Azj4afUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(img_path, model):\n",
        "    def Get_img(images_path, transformation):\n",
        "        img = PIL.Image.open(images_path)\n",
        "        if transformation : \n",
        "          img = transformation(img)\n",
        "        return img\n",
        "\n",
        "    img = Get_img(img_path, transformation = transformation)\n",
        "    img = img[None, :, :, :]\n",
        "    label_encode = {\n",
        "        'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'del': 26, 'nothing': 27, 'space': 28\n",
        "    }\n",
        "    label_decode = {value: key for key, value in label_encode.items()}\n",
        "    prediction = model(img.cuda())\n",
        "    print('Predicted As :',label_decode[int(prediction.argmax())])\n",
        "    images = cv2.imread(img_path)\n",
        "    images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(images)\n",
        "    \n",
        "    return torch.softmax(prediction,dim=1)\n",
        "prediction = predict(images, new_model)\n",
        "print(torch.round(prediction * 100,decimals=1))"
      ],
      "metadata": {
        "id": "5_4JsgCiarFB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}