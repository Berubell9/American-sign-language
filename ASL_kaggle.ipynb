{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# American Sign Languege (ASL)\n",
        "นำ Dataset มาจากเว็บไซต์ Kaggle : \n",
        "[ASL(American Sign Language) Alphabet Dataset](https://www.kaggle.com/datasets/debashishsau/aslamerican-sign-language-aplhabet-dataset)\n",
        "\n",
        "การนำ Dataset จากเว็บไซต์ Kaggle มาใช้ต้องอัปโหลด **kaggle.json** เข้าไปที่ `... /root/ .kaggle` \n",
        "\n",
        "[วิธีอัปโหลด Dataset จากเว็บไซต์ Kaggle]( https://www.youtube.com/watch?v=57N1g8k2Hwc)"
      ],
      "metadata": {
        "id": "Ou5DWTgFzngL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fthHHlcuL7_H"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKCt2VdNyRwD"
      },
      "outputs": [],
      "source": [
        "# สร้างโฟลเดอร์ .kaggle เเละอัปโหลด kaggle.json\n",
        "! mkdir ./.kaggle\n",
        "! cp kaggle.json ./.kaggle/\n",
        "! chmod 600 ./.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq9Zc30uDTv_"
      },
      "outputs": [],
      "source": [
        "# อัปโหลด API เพื่อดาวโหลด Dataset ใน kaggle\n",
        "! kaggle datasets download -d debashishsau/aslamerican-sign-language-aplhabet-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLwlX7mOEfCO"
      },
      "outputs": [],
      "source": [
        "# unzip Dataset\n",
        "! unzip aslamerican-sign-language-aplhabet-dataset.zip -d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci9XVrX2FbgR"
      },
      "outputs": [],
      "source": [
        "! pip install torchvision\n",
        "! pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDRkVqI3FnRP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os.path as op\n",
        "import shutil\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision import datasets, models, transforms\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "import torch\n",
        "import PIL\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lG4lE5fWHEJn"
      },
      "outputs": [],
      "source": [
        "# ดึงรูปจากใน class train\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, train_dir,transformation):\n",
        "        self.img_labels = []\n",
        "        self.img_dirs = []\n",
        "        self.transformation = transformation\n",
        "        \n",
        "        for label in listdir(train_dir):\n",
        "            img_dirs_in_folder = [join(train_dir, label, file_name) for file_name in listdir(join(train_dir, label)) if isfile(join(train_dir, label, file_name))]\n",
        "            self.img_dirs.extend(img_dirs_in_folder)\n",
        "            self.img_labels.extend([label] * len(img_dirs_in_folder))\n",
        "            \n",
        "        self.labels_encode = {class_name: i for i , class_name in enumerate(sorted(set(self.img_labels)))}    \n",
        "    def __len__(self):\n",
        "        return len(self.img_dirs)\n",
        "    \n",
        "    def _read_img(self, img_dir):\n",
        "        return PIL.Image.open(img_dir)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img = self._read_img(self.img_dirs[index])\n",
        "        if self.transformation : \n",
        "          img = self.transformation(img)\n",
        "        label = self.img_labels[index]\n",
        "        label = self.labels_encode[label]\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juFEjWKmeHzU"
      },
      "outputs": [],
      "source": [
        "# ปรับขนาดรูปภาพให้เป็น 224*224\n",
        "transformation = transforms.Compose([\n",
        "  transforms.Resize((224,224)),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])                                   \n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8UxKvxsYJlF",
        "outputId": "2a0ec7c9-3e08-4198-d565-ef163714d085"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "train[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a2ZeXvcHlQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cca72d7-0a68-4da4-c2a2-dbc163d7ad96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'del': 26, 'nothing': 27, 'space': 28}\n"
          ]
        }
      ],
      "source": [
        "# Dataset ทั้งหมด 29 class\n",
        "train_dataset = CustomDataset(\"/content/data/ASL_Alphabet_Dataset/asl_alphabet_train\",transformation = transformation)\n",
        "print(train_dataset.labels_encode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrNiJgMQPRCY"
      },
      "source": [
        "# Data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqVMNzgBRNf3"
      },
      "outputs": [],
      "source": [
        "# สร้าง pretrained model เป็น resnet34\n",
        "model = models.resnet34(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model ที่เอามา Train ต่อ\n",
        "# model = torch.load(f\"/content/drive/MyDrive/ASL_20classify.pt\")"
      ],
      "metadata": {
        "id": "CYQdl-4-eIfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#(fc): Linear(in_features=512, out_features=1000, bias=True) มาจาก print(model)\n",
        "model.fc = nn.Linear(512, 29)"
      ],
      "metadata": {
        "id": "puEi1QzcOhwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NLt20pyzmZd",
        "outputId": "1ce76af3-192d-4ac0-fc8f-b0bda839de77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        " torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5z-GEClXBD1",
        "outputId": "5469e70c-0afa-48ac-cd86-d2ee1eb05651"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "223074"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# จำนวนข้อมูลทั้งหมด\n",
        "len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAdXJV2oVJMe"
      },
      "outputs": [],
      "source": [
        "# เเบ่ง train ,test\n",
        "train,test = torch.utils.data.random_split(train_dataset,[223074-20000,20000])\n",
        "train_loader = DataLoader(train, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSOnCyJxYPTS"
      },
      "outputs": [],
      "source": [
        "# สร้าง loss, optimizer\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=2e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt_D4MVUY21g",
        "outputId": "62b6a0da-4692-4d79-edcd-e5f9f6a8bc9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# เช็คว่ามี GPU ที่สามารถใช้ได้มั้ย ถ้าใช้ได้นำโมเดลเข้าไปอยู่ใน GPU\n",
        "gpu = torch.cuda.is_available()\n",
        "print(gpu)\n",
        "if gpu:\n",
        "    model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0DFaEfzcPbi"
      },
      "source": [
        "# Train Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bp0IzFGhcqAj"
      },
      "outputs": [],
      "source": [
        "n_train = len(train_loader.dataset)\n",
        "n_val = len(test_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbWy99OjY3b6"
      },
      "outputs": [],
      "source": [
        "n_epochs = 1 # จำนวนรอบ\n",
        "for epoch in range(n_epochs):\n",
        "    # ช่วง train\n",
        "    model.train()\n",
        "    train_loss, val_loss = 0, 0\n",
        "    for images, labels in tqdm(train_loader):\n",
        "        if gpu:\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(images) # คำนวณหา output (pred) จากโมเดลที่มีอยู่\n",
        "        loss = cross_entropy(pred, labels)\n",
        "        loss.backward() # คำนวณ gradient จาก loss ที่ได้\n",
        "        optimizer.step() # อัพเดทพารามิเตอร์ของโมเดล\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "\n",
        "    # ช่วง validate\n",
        "    model.eval() # เซ็ตเป็น evaluation mode\n",
        "    torch.save(model,f\"/content/drive/MyDrive/ชื่อไฟล์.pt\") # save model\n",
        "    for images, labels in tqdm(test_loader):\n",
        "        if gpu:\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "        pred = model(images)\n",
        "        loss = cross_entropy(pred, labels)\n",
        "        val_loss += loss.item() * images.size(0)\n",
        "    print(\"Training loss = {}, Validation loss = {}\".format(train_loss / n_train, val_loss / n_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnMH3EcLDQx1"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUwTsTQKDal_"
      },
      "outputs": [],
      "source": [
        "# ใส่ Path โมเดล\n",
        "new_model = torch.load(f\"...\")#โหลดโมเดล\n",
        "new_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhyFjU_l0ttH"
      },
      "outputs": [],
      "source": [
        "pred_list = []\n",
        "label_list = []\n",
        "for data, label in tqdm(test_loader):\n",
        "  pred = new_model(data.cuda()).cpu().detach()\n",
        "  pred = torch.argmax(torch.softmax(pred,dim=1),dim=1)\n",
        "  pred_list.extend(pred.numpy().tolist())\n",
        "  label_list.extend(label.numpy().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66lmbt-77bQE"
      },
      "outputs": [],
      "source": [
        "label_encode = {\n",
        "        'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'del': 26, 'nothing': 27, 'space': 28\n",
        "    }\n",
        "label_decode = {value: key for key, value in label_encode.items()}\n",
        "\n",
        "pred_key = [label_decode[pred] for pred in pred_list]\n",
        "label_key = [label_decode[label] for label in label_list]\n",
        "labels = list(label_encode.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2XDo9yg6m2T"
      },
      "outputs": [],
      "source": [
        "cfm = confusion_matrix(label_key ,pred_key, labels = list(label_encode.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogJLELD9CB6f"
      },
      "outputs": [],
      "source": [
        "# ความเเม่นยำ(Accuracy) ของทุกคลาส ,ทั้งหมด \n",
        "df_cm = pd.DataFrame(cfm/np.sum(cfm, axis = -1) *100, index = [i for i in labels],columns = [i for i in labels])\n",
        "plt.figure(figsize = (12*2,7*2))\n",
        "sns.heatmap(df_cm, annot=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwbP36IDF-Vo"
      },
      "outputs": [],
      "source": [
        "# ความเเม่นยำ(Accuracy) ของทุกคลาส ,ทั้งหมด \n",
        "rint(classification_report(label_key ,pred_key, labels = list(label_encode.keys())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "286yhUuXeaxv"
      },
      "source": [
        "# ทำนายผลจาก Test ข้างนอก (Predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obCeYYRqQqLT"
      },
      "outputs": [],
      "source": [
        "# ใส่ Path ภาพ\n",
        "images = '...' \n",
        "\n",
        "# ใส่ Path โมเดล\n",
        "new_model = torch.load(f\"...\")\n",
        "new_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fIqNYYDdy8b"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "def predict(img_path, model):\n",
        "    def Get_img(images_path, transformation):\n",
        "        img = PIL.Image.open(images_path)\n",
        "        if transformation : \n",
        "          img = transformation(img)\n",
        "        return img\n",
        "\n",
        "    img = Get_img(img_path, transformation = transformation)\n",
        "    img = img[None, :, :, :]\n",
        "    label_encode = {\n",
        "        'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'del': 26, 'nothing': 27, 'space': 28\n",
        "    }\n",
        "    label_decode = {value: key for key, value in label_encode.items()}\n",
        "    prediction = model(img.cuda())\n",
        "    print('Predicted As :',label_decode[int(prediction.argmax())])\n",
        "    images = cv2.imread(img_path)\n",
        "    images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(images)\n",
        "    \n",
        "    return torch.softmax(prediction,dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOOp90XWd4Ja"
      },
      "outputs": [],
      "source": [
        "prediction = predict(images, new_model)\n",
        "print(torch.round(prediction * 100,decimals=1))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ASL_kaggle.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}